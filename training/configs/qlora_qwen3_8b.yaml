# QLoRA SFT config for Qwen3-8B (Windows / RTX 4070 SUPER)
base: "Qwen/Qwen3-8B"

train_file: "training/data/train.jsonl"
val_file:   "training/data/val.jsonl"

max_seq_len: 1536  # 메모리 절약을 위해 1536으로 감소

lora:
  r: 16            # 메모리 절약을 위해 16으로 감소
  alpha: 32
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - up_proj
    - down_proj
    - gate_proj

precision:
  bf16: true
  fp16: false

gradient_checkpointing: true

optimizer:
  name: "paged_adamw_8bit"        # bitsandbytes 필요
  lr: 2.0e-4
  warmup_ratio: 0.03

training:
  epochs: 1
  batch_size: 1
  grad_accum: 32    # 메모리 절약을 위해 32로 증가 (유효 배치 크기 유지)
  logging_steps: 10
  eval_steps: 200
  save_steps: 200
  output_dir: "training/qlora-out"

